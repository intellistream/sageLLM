name: sageLLM CI

on:
  push:
    branches:
      - main
      - main-dev
  pull_request:
    branches:
      - main
      - main-dev
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PIP_DISABLE_PIP_VERSION_CHECK: "1"
  PYTHONWARNINGS: "ignore:::pip._internal.cli.base_command"
  UV_SYSTEM_PYTHON: "1"

jobs:
  lint:
    name: Lint & Static Analysis
    runs-on: ubuntu-22.04
    timeout-minutes: 35

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: |
            requirements/dev.txt
            .pre-commit-config.yaml

      - name: Install lint toolchain
        run: |
          python -m pip install --upgrade pip
          pip install pre-commit

      - name: Run pre-commit (default hooks)
        run: pre-commit run --all-files --show-diff-on-failure

      - name: Run pre-commit (manual hooks)
        run: pre-commit run --all-files --hook-stage manual --show-diff-on-failure

  build-and-test:
    name: Build (CPU) & Smoke Tests
    runs-on: ubuntu-22.04
    needs: lint
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.10", "3.11"]
    timeout-minutes: 60
    env:
      VLLM_TARGET_DEVICE: cpu
      PYTHONUNBUFFERED: "1"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: pip
          cache-dependency-path: |
            requirements/cpu-build.txt
            requirements/common.txt

      - name: Install system dependencies
        run: |
          sudo apt-get update -y
          sudo apt-get install -y build-essential ninja-build cmake

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip wheel setuptools
          pip install --upgrade --extra-index-url https://download.pytorch.org/whl/cpu torch==2.8.0+cpu \
            || pip install --pre --upgrade --extra-index-url https://download.pytorch.org/whl/cpu torch==2.8.0+cpu \
            || pip install --pre --upgrade --extra-index-url https://download.pytorch.org/whl/cpu torch==2.8.0 \
            || pip install --upgrade --extra-index-url https://download.pytorch.org/whl/cpu torch
          pip install -r requirements/common.txt
          pip install pytest pytest-xdist pytest-cov
        env:
          PIP_EXTRA_INDEX_URL: https://download.pytorch.org/whl/cpu

      - name: Prepare source package for testing
        run: |
          echo "PYTHONPATH=${PYTHONPATH}:$PWD" >> "$GITHUB_ENV"

      - name: Run targeted smoke tests
        run: |
          pytest \
            tests/test_version.py \
            tests/test_logger.py::test_default_vllm_root_logger_configuration \
            tests/test_logger.py::test_logger_configuring_can_be_disabled \
            tests/test_logger.py::test_trace_function_call \
            tests/test_envs.py

      - name: Verify import of key modules
        run: |
          python - <<'PY'
          import vllm
          from vllm import logger
          from vllm.entrypoints.logger import RequestLogger
          print("vLLM version:", vllm.__version__)
          print("Logger module available:", logger.__name__)
          print("RequestLogger class:", RequestLogger)
          PY

      - name: Upload pytest report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pytest-logs-${{ matrix.python-version }}
          path: |
            .pytest_cache
            **/.pytest_cache
            tests/__pycache__
          if-no-files-found: ignore

  gpu-tests:
    name: GPU Functional Tests
    runs-on:
      - self-hosted
      - linux
      - gpu
    needs:
      - build-and-test
    timeout-minutes: 70
    env:
      VLLM_TARGET_DEVICE: cuda
      PYTHONUNBUFFERED: "1"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Show GPU info
        run: |
          nvidia-smi || true

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: |
            requirements/cuda.txt
            requirements/common.txt

      - name: Install CUDA Python dependencies
        env:
          TORCH_CUDA_CHANNEL: https://download.pytorch.org/whl
        run: |
          python -m pip install --upgrade pip wheel setuptools
          pip install --upgrade --index-url ${TORCH_CUDA_CHANNEL}/cu128 torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 \
            || pip install --upgrade --index-url ${TORCH_CUDA_CHANNEL}/cu124 torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 \
            || pip install --upgrade --index-url ${TORCH_CUDA_CHANNEL}/cu121 torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 \
            || pip install torch torchvision torchaudio --index-url ${TORCH_CUDA_CHANNEL}/cu118
          pip install -r requirements/common.txt
          pip install "ray[cgraph]>=2.48.0"
          if [[ "$(uname -m)" == "x86_64" ]]; then
            pip install xformers==0.0.32.post1
          fi
          pip install pytest pytest-xdist pytest-cov

      - name: Verify CUDA availability
        run: |
          python - <<'PY'
          import torch
          assert torch.cuda.is_available(), "CUDA device is required for GPU tests"
          print("CUDA devices:", torch.cuda.device_count())
          print("Primary device:", torch.cuda.get_device_name(0))
          PY

      - name: Run CUDA smoke tests
        run: |
          pytest tests/cuda/test_cuda_context.py -v

      - name: Import vLLM with CUDA
        run: |
          python - <<'PY'
          import vllm
          from vllm.platforms import current_platform
          print("vLLM version:", vllm.__version__)
          print("Current platform reports CUDA:", current_platform.is_cuda())
          PY

      - name: Upload GPU pytest artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pytest-logs-gpu
          path: |
            .pytest_cache
            **/.pytest_cache
            tests/__pycache__
          if-no-files-found: ignore
