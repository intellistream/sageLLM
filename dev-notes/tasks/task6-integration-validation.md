# Task 6: æ¨¡å—é›†æˆä¸ç«¯åˆ°ç«¯éªŒè¯

**çŠ¶æ€**: ğŸ”² å¾…å¼€å§‹  
**é¢„è®¡æ—¶é—´**: 4h  
**ä¾èµ–**: Task 1-5 å…¨éƒ¨å®Œæˆ  
**å¯å¹¶è¡Œ**: âŒ å¦ï¼ˆä¾èµ–æ‰€æœ‰å‰ç½®ä»»åŠ¡ï¼‰

---

## èƒŒæ™¯

Task 1-5 åˆ†åˆ«å®ç°äº†å„ä¸ªæ¨¡å—ï¼š
- Task 1: `runtime/` (execution_graph, scheduler)
- Task 2: `kv_runtime/` (å¤šç²’åº¦ KV ç®¡ç†)
- Task 3: `accel/` (é‡åŒ–ã€ç¨€ç–)
- Task 4: `backends/` (ç¡¬ä»¶æŠ½è±¡)
- Task 5: `benchmarks/` (è¯„æµ‹æ¡†æ¶)

æœ¬ä»»åŠ¡è´Ÿè´£å°†è¿™äº›æ¨¡å—é›†æˆèµ·æ¥ï¼Œç¡®ä¿å®ƒä»¬èƒ½å¤ŸååŒå·¥ä½œã€‚

---

## å·¥ä½œç›®å½•

```
/home/shuhao/SAGE/packages/sage-common/src/sage/common/components/sage_llm/sageLLM/
â”œâ”€â”€ __init__.py              # æ›´æ–°ä¸»å…¥å£
â”œâ”€â”€ engine.py                # ğŸ†• æ¨ç†å¼•æ“ï¼ˆé›†æˆå±‚ï¼‰
â”œâ”€â”€ config.py                # ğŸ†• ç»Ÿä¸€é…ç½®
â””â”€â”€ examples/                # ğŸ†• ç¤ºä¾‹
    â”œâ”€â”€ __init__.py
    â””â”€â”€ basic_inference.py
```

---

## ä»»åŠ¡æ¸…å•

### 1. ç»Ÿä¸€é…ç½® (`config.py`)

```python
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any
from enum import Enum, auto
from pathlib import Path

from .backends import BackendType
from .accel.quantize import QuantizationType
from .accel.sparsity.structured import SparsityPattern
from .kv_runtime.blocks.multi_granular import KVGranularity, StorageTier
from .runtime.scheduler.pd_scheduler import ScheduleMode


class InferenceMode(Enum):
    """æ¨ç†æ¨¡å¼"""
    STANDARD = auto()      # æ ‡å‡†æ¨ç†
    PREFILL_ONLY = auto()  # ä»… prefill
    DECODE_ONLY = auto()   # ä»… decode
    PD_SEPARATE = auto()   # PD åˆ†ç¦»


@dataclass
class ModelConfig:
    """æ¨¡å‹é…ç½®"""
    model_id: str
    
    # æ¨¡å‹ç»“æ„
    num_layers: int = 32
    num_heads: int = 32
    hidden_size: int = 4096
    vocab_size: int = 32000
    max_seq_len: int = 4096
    
    # ç²¾åº¦
    dtype: str = "float16"
    
    # é‡åŒ–
    quantization: Optional[QuantizationType] = None
    quantization_config: Dict[str, Any] = field(default_factory=dict)
    
    # ç¨€ç–
    sparsity_pattern: Optional[SparsityPattern] = None
    sparsity_ratio: float = 0.0


@dataclass
class KVCacheConfig:
    """KV ç¼“å­˜é…ç½®"""
    # å®¹é‡
    max_tokens: int = 65536
    block_size: int = 16
    
    # ç²’åº¦
    granularity: KVGranularity = KVGranularity.BLOCK
    
    # åˆ†å±‚å­˜å‚¨
    enable_tiering: bool = False
    hbm_ratio: float = 0.7      # HBM å æ¯”
    ddr_ratio: float = 0.2      # DDR å æ¯”
    nvme_ratio: float = 0.1     # NVMe å æ¯”
    nvme_path: Optional[str] = None
    
    # å¤ç”¨
    enable_prefix_caching: bool = True
    enable_cross_request_sharing: bool = True
    
    # è¿ç§»
    enable_migration: bool = True
    hot_threshold: float = 1.0   # çƒ­å—è®¿é—®é¢‘ç‡é˜ˆå€¼
    cold_timeout_s: float = 60.0  # å†·å—è¶…æ—¶


@dataclass
class SchedulerConfig:
    """è°ƒåº¦å™¨é…ç½®"""
    # æ¨¡å¼
    mode: ScheduleMode = ScheduleMode.HYBRID
    
    # PD åˆ†ç¦»
    prefill_workers: int = 1
    decode_workers: int = 1
    
    # æ‰¹å¤„ç†
    max_batch_size: int = 64
    max_prefill_batch: int = 8
    max_decode_batch: int = 64
    
    # è¶…æ—¶
    request_timeout_s: float = 60.0
    queue_timeout_s: float = 30.0


@dataclass
class BackendConfig:
    """åç«¯é…ç½®"""
    # ç¡¬ä»¶
    backend_type: Optional[BackendType] = None  # None = è‡ªåŠ¨æ£€æµ‹
    device_ids: List[int] = field(default_factory=lambda: [0])
    
    # åˆ†å¸ƒå¼
    tensor_parallel_size: int = 1
    pipeline_parallel_size: int = 1


@dataclass
class BenchmarkConfig:
    """è¯„æµ‹é…ç½®"""
    # å¯ç”¨
    enable_profiling: bool = False
    enable_metrics: bool = True
    
    # CI é—¨æ§
    enable_gates: bool = False
    min_throughput_tps: Optional[float] = None
    max_ttft_ms: Optional[float] = None
    max_tpot_ms: Optional[float] = None


@dataclass
class SageLLMConfig:
    """sageLLM ç»Ÿä¸€é…ç½®"""
    model: ModelConfig
    kv_cache: KVCacheConfig = field(default_factory=KVCacheConfig)
    scheduler: SchedulerConfig = field(default_factory=SchedulerConfig)
    backend: BackendConfig = field(default_factory=BackendConfig)
    benchmark: BenchmarkConfig = field(default_factory=BenchmarkConfig)
    
    # æ¨ç†æ¨¡å¼
    inference_mode: InferenceMode = InferenceMode.STANDARD
    
    @classmethod
    def from_yaml(cls, path: str) -> "SageLLMConfig":
        """ä» YAML æ–‡ä»¶åŠ è½½é…ç½®"""
        import yaml
        with open(path) as f:
            data = yaml.safe_load(f)
        return cls._from_dict(data)
    
    @classmethod
    def _from_dict(cls, data: Dict) -> "SageLLMConfig":
        """ä»å­—å…¸åˆ›å»ºé…ç½®"""
        model = ModelConfig(**data.get("model", {}))
        kv_cache = KVCacheConfig(**data.get("kv_cache", {}))
        scheduler = SchedulerConfig(**data.get("scheduler", {}))
        backend = BackendConfig(**data.get("backend", {}))
        benchmark = BenchmarkConfig(**data.get("benchmark", {}))
        
        return cls(
            model=model,
            kv_cache=kv_cache,
            scheduler=scheduler,
            backend=backend,
            benchmark=benchmark,
        )
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        import dataclasses
        return dataclasses.asdict(self)
```

### 2. æ¨ç†å¼•æ“é›†æˆ (`engine.py`)

```python
from dataclasses import dataclass
from typing import Dict, List, Optional, Any, AsyncIterator
import logging
import asyncio

from .config import SageLLMConfig, InferenceMode
from .backends import get_backend, HardwareBackend, DeviceInfo
from .runtime.execution_graph import ExecutionGraph, ExecutionGraphBuilder
from .runtime.scheduler import PDScheduler, ScheduleOutput
from .kv_runtime.blocks.multi_granular import MultiGranularKVPool, KVPoolConfig
from .kv_runtime.hierarchy.tiered_storage import TieredKVStorage, TierConfig
from .kv_runtime.reuse.cross_request import CrossRequestKVCache
from .accel.quantize import QuantizerRegistry
from .benchmarks.metrics import MetricRegistry
from .benchmarks.metrics.throughput import ThroughputMetric
from .benchmarks.metrics.latency import LatencyMetric

logger = logging.getLogger(__name__)


@dataclass
class GenerateRequest:
    """ç”Ÿæˆè¯·æ±‚"""
    request_id: str
    prompt_tokens: List[int]
    max_new_tokens: int = 128
    temperature: float = 1.0
    top_p: float = 1.0
    stop_sequences: Optional[List[str]] = None


@dataclass
class GenerateOutput:
    """ç”Ÿæˆè¾“å‡º"""
    request_id: str
    output_tokens: List[int]
    finish_reason: str  # "length", "stop", "error"
    metrics: Optional[Dict[str, float]] = None


class SageLLMEngine:
    """sageLLM æ¨ç†å¼•æ“
    
    é›†æˆæ‰€æœ‰æ¨¡å—ï¼Œæä¾›ç»Ÿä¸€çš„æ¨ç†æ¥å£ã€‚
    
    Usage:
        config = SageLLMConfig(...)
        engine = SageLLMEngine(config)
        engine.initialize()
        
        request = GenerateRequest(
            request_id="req_1",
            prompt_tokens=[1, 2, 3],
            max_new_tokens=100,
        )
        
        output = engine.generate(request)
    """
    
    def __init__(self, config: SageLLMConfig):
        self.config = config
        
        # ç»„ä»¶ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self._backend: Optional[HardwareBackend] = None
        self._scheduler: Optional[PDScheduler] = None
        self._kv_pool: Optional[MultiGranularKVPool] = None
        self._kv_cache: Optional[CrossRequestKVCache] = None
        self._kv_storage: Optional[TieredKVStorage] = None
        
        # æŒ‡æ ‡
        self._throughput_metric: Optional[ThroughputMetric] = None
        self._latency_metric: Optional[LatencyMetric] = None
        
        # çŠ¶æ€
        self._initialized = False
    
    def initialize(self) -> None:
        """åˆå§‹åŒ–å¼•æ“"""
        if self._initialized:
            logger.warning("Engine already initialized")
            return
        
        logger.info(f"Initializing sageLLM engine for {self.config.model.model_id}")
        
        # 1. åˆå§‹åŒ–ç¡¬ä»¶åç«¯
        self._init_backend()
        
        # 2. åˆå§‹åŒ– KV ç¼“å­˜
        self._init_kv_cache()
        
        # 3. åˆå§‹åŒ–è°ƒåº¦å™¨
        self._init_scheduler()
        
        # 4. åˆå§‹åŒ–æŒ‡æ ‡
        if self.config.benchmark.enable_metrics:
            self._init_metrics()
        
        self._initialized = True
        logger.info("Engine initialization complete")
    
    def _init_backend(self) -> None:
        """åˆå§‹åŒ–ç¡¬ä»¶åç«¯"""
        backend_type = self.config.backend.backend_type
        self._backend = get_backend(backend_type)
        
        device_info = self._backend.get_device_info()
        logger.info(f"Using backend: {device_info.name}")
        logger.info(f"  Memory: {device_info.total_memory_gb:.1f} GB")
        logger.info(f"  Capabilities: {self._backend.get_capabilities()}")
    
    def _init_kv_cache(self) -> None:
        """åˆå§‹åŒ– KV ç¼“å­˜"""
        kv_config = self.config.kv_cache
        
        # åˆ›å»º KV æ± 
        pool_config = KVPoolConfig(
            block_size=kv_config.block_size,
            default_granularity=kv_config.granularity,
            enable_sharing=kv_config.enable_cross_request_sharing,
            enable_tiering=kv_config.enable_tiering,
        )
        self._kv_pool = MultiGranularKVPool(pool_config)
        
        # åˆ›å»ºè·¨è¯·æ±‚ç¼“å­˜
        self._kv_cache = CrossRequestKVCache(
            pool=self._kv_pool,
            enable_tenant_isolation=False,
        )
        
        # å¦‚æœå¯ç”¨åˆ†å±‚å­˜å‚¨
        if kv_config.enable_tiering:
            from .kv_runtime.blocks.multi_granular import StorageTier
            device_info = self._backend.get_device_info()
            
            hbm_capacity = int(device_info.total_memory_gb * kv_config.hbm_ratio * 1024**3)
            ddr_capacity = int(64 * kv_config.ddr_ratio * 1024**3)  # å‡è®¾ 64GB ä¸»å­˜
            
            self._kv_storage = TieredKVStorage(
                hbm_config=TierConfig(
                    tier=StorageTier.HBM,
                    capacity_bytes=hbm_capacity,
                    bandwidth_gbps=2000.0,
                    latency_us=1.0,
                    device_id=self.config.backend.device_ids[0],
                ),
                ddr_config=TierConfig(
                    tier=StorageTier.DDR,
                    capacity_bytes=ddr_capacity,
                    bandwidth_gbps=50.0,
                    latency_us=100.0,
                ),
            )
        
        logger.info(f"KV cache initialized: block_size={kv_config.block_size}")
    
    def _init_scheduler(self) -> None:
        """åˆå§‹åŒ–è°ƒåº¦å™¨"""
        sched_config = self.config.scheduler
        
        from .runtime.scheduler.pd_scheduler import PDSchedulerConfig
        
        scheduler_config = PDSchedulerConfig(
            mode=sched_config.mode,
            prefill_workers=sched_config.prefill_workers,
            decode_workers=sched_config.decode_workers,
            max_batch_size=sched_config.max_batch_size,
        )
        
        self._scheduler = PDScheduler(scheduler_config)
        logger.info(f"Scheduler initialized: mode={sched_config.mode.name}")
    
    def _init_metrics(self) -> None:
        """åˆå§‹åŒ–æŒ‡æ ‡"""
        self._throughput_metric = ThroughputMetric()
        self._latency_metric = LatencyMetric()
        logger.info("Metrics initialized")
    
    def generate(self, request: GenerateRequest) -> GenerateOutput:
        """åŒæ­¥ç”Ÿæˆ
        
        Args:
            request: ç”Ÿæˆè¯·æ±‚
            
        Returns:
            ç”Ÿæˆè¾“å‡º
        """
        if not self._initialized:
            raise RuntimeError("Engine not initialized. Call initialize() first.")
        
        # å¼€å§‹è®¡æ—¶
        if self._latency_metric:
            self._latency_metric.request_start()
        
        if self._throughput_metric:
            self._throughput_metric.start()
        
        # 1. å°è¯• KV å¤ç”¨
        reuse_result = self._kv_cache.try_reuse(
            request_id=request.request_id,
            token_ids=request.prompt_tokens,
        )
        
        if reuse_result.reused:
            logger.debug(f"KV reuse: {reuse_result.matched_tokens}/{reuse_result.total_tokens} tokens")
            # ä»å¤ç”¨ç‚¹å¼€å§‹ç”Ÿæˆ
            start_pos = reuse_result.matched_tokens
        else:
            start_pos = 0
        
        # 2. æ„å»ºæ‰§è¡Œå›¾
        builder = ExecutionGraphBuilder(
            num_layers=self.config.model.num_layers,
            num_heads=self.config.model.num_heads,
            hidden_size=self.config.model.hidden_size,
        )
        
        # Prefill å›¾ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if start_pos < len(request.prompt_tokens):
            prefill_graph = builder.build_prefill_graph(
                seq_len=len(request.prompt_tokens) - start_pos,
            )
        
        # 3. è°ƒåº¦æ‰§è¡Œï¼ˆç®€åŒ–å®ç°ï¼‰
        output_tokens = []
        
        # Prefill é˜¶æ®µ
        if self._latency_metric:
            self._latency_metric.prefill_done()
            self._latency_metric.first_token()
        
        # Decode é˜¶æ®µï¼ˆæ¨¡æ‹Ÿï¼‰
        for i in range(request.max_new_tokens):
            # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„æ¨¡å‹æ¨ç†
            # ç®€åŒ–ä¸ºç”Ÿæˆå ä½ç¬¦
            new_token = i + 1000  # placeholder
            output_tokens.append(new_token)
            
            if self._latency_metric:
                self._latency_metric.token_generated()
        
        # 4. è®¡ç®—æŒ‡æ ‡
        metrics = None
        if self._throughput_metric:
            self._throughput_metric.record(
                tokens=len(output_tokens),
                requests=1,
            )
            throughput_result = self._throughput_metric.compute()
            
            latency_result = self._latency_metric.compute() if self._latency_metric else None
            
            metrics = {
                "throughput_tps": throughput_result.tokens_per_second,
                "ttft_ms": latency_result.ttft_ms if latency_result else 0,
                "tpot_ms": latency_result.tpot_ms if latency_result else 0,
            }
        
        # 5. æäº¤ KV ä¾›å¤ç”¨
        if self.config.kv_cache.enable_prefix_caching:
            # åˆ†é…æ–°çš„ KV å—
            new_blocks = self._kv_pool.allocate(
                sequence_id=hash(request.request_id),
                request_id=request.request_id,
                num_tokens=len(request.prompt_tokens),
                layer_ids=list(range(self.config.model.num_layers)),
            )
            self._kv_cache.commit(
                request_id=request.request_id,
                token_ids=request.prompt_tokens,
                blocks=new_blocks,
            )
        
        return GenerateOutput(
            request_id=request.request_id,
            output_tokens=output_tokens,
            finish_reason="length",
            metrics=metrics,
        )
    
    async def generate_async(
        self,
        request: GenerateRequest,
    ) -> GenerateOutput:
        """å¼‚æ­¥ç”Ÿæˆ"""
        # ç®€åŒ–å®ç°ï¼šåŒ…è£…åŒæ­¥æ–¹æ³•
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, self.generate, request)
    
    async def generate_stream(
        self,
        request: GenerateRequest,
    ) -> AsyncIterator[int]:
        """æµå¼ç”Ÿæˆ"""
        if not self._initialized:
            raise RuntimeError("Engine not initialized")
        
        # ç®€åŒ–å®ç°ï¼šé€ token yield
        for i in range(request.max_new_tokens):
            yield i + 1000  # placeholder
            await asyncio.sleep(0.001)  # æ¨¡æ‹Ÿå»¶è¿Ÿ
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "initialized": self._initialized,
            "backend": self._backend.backend_type.name if self._backend else None,
        }
        
        if self._kv_pool:
            stats["kv_pool"] = self._kv_pool.get_stats()
        
        if self._kv_cache:
            stats["kv_cache"] = self._kv_cache.get_stats()
        
        return stats
    
    def shutdown(self) -> None:
        """å…³é—­å¼•æ“"""
        logger.info("Shutting down engine")
        
        # æ¸…ç†èµ„æº
        if self._backend:
            self._backend.empty_cache()
        
        self._initialized = False
```

### 3. ç¤ºä¾‹ä»£ç  (`examples/basic_inference.py`)

```python
#!/usr/bin/env python3
"""sageLLM åŸºæœ¬æ¨ç†ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ sageLLM å¼•æ“è¿›è¡Œæ¨ç†ã€‚
"""

import logging
from sageLLM.config import SageLLMConfig, ModelConfig, KVCacheConfig
from sageLLM.engine import SageLLMEngine, GenerateRequest

logging.basicConfig(level=logging.INFO)


def main():
    # 1. åˆ›å»ºé…ç½®
    config = SageLLMConfig(
        model=ModelConfig(
            model_id="Qwen/Qwen2.5-7B-Instruct",
            num_layers=32,
            num_heads=32,
            hidden_size=4096,
        ),
        kv_cache=KVCacheConfig(
            max_tokens=65536,
            enable_prefix_caching=True,
        ),
    )
    
    # 2. åˆå§‹åŒ–å¼•æ“
    engine = SageLLMEngine(config)
    engine.initialize()
    
    print(f"Engine stats: {engine.get_stats()}")
    
    # 3. å‘é€è¯·æ±‚
    request = GenerateRequest(
        request_id="test_001",
        prompt_tokens=[1, 2, 3, 4, 5],  # å®é™…åº”è¯¥æ˜¯ tokenized çš„è¾“å…¥
        max_new_tokens=50,
    )
    
    output = engine.generate(request)
    
    print(f"\nGeneration result:")
    print(f"  Request ID: {output.request_id}")
    print(f"  Output tokens: {len(output.output_tokens)}")
    print(f"  Finish reason: {output.finish_reason}")
    
    if output.metrics:
        print(f"  Throughput: {output.metrics['throughput_tps']:.1f} tokens/s")
        print(f"  TTFT: {output.metrics['ttft_ms']:.1f} ms")
        print(f"  TPOT: {output.metrics['tpot_ms']:.1f} ms")
    
    # 4. æµ‹è¯• KV å¤ç”¨
    print("\n--- Testing KV reuse ---")
    
    # ä½¿ç”¨ç›¸åŒå‰ç¼€çš„è¯·æ±‚
    request2 = GenerateRequest(
        request_id="test_002",
        prompt_tokens=[1, 2, 3, 4, 5, 6, 7],  # åŒ…å«ç›¸åŒå‰ç¼€
        max_new_tokens=30,
    )
    
    output2 = engine.generate(request2)
    print(f"Second request completed with KV reuse")
    
    # 5. æŸ¥çœ‹ç»Ÿè®¡
    print(f"\nFinal stats: {engine.get_stats()}")
    
    # 6. å…³é—­
    engine.shutdown()


if __name__ == "__main__":
    main()
```

### 4. æ›´æ–°ä¸»å…¥å£ (`__init__.py`)

```python
"""sageLLM: SAGE è‡ªç ” LLM æ¨ç†è¿è¡Œæ—¶

sageLLM æä¾›é«˜æ€§èƒ½ LLM æ¨ç†èƒ½åŠ›ï¼Œæ”¯æŒï¼š
- PD åˆ†ç¦»è°ƒåº¦
- å¤šç²’åº¦ KV ç¼“å­˜ç®¡ç†
- æ¨¡å‹é‡åŒ–ä¸ç¨€ç–
- å›½äº§èŠ¯ç‰‡æ”¯æŒ

Quick Start:
    from sageLLM import SageLLMEngine, SageLLMConfig, ModelConfig
    
    config = SageLLMConfig(
        model=ModelConfig(model_id="Qwen/Qwen2.5-7B-Instruct"),
    )
    
    engine = SageLLMEngine(config)
    engine.initialize()
    
    output = engine.generate(GenerateRequest(
        request_id="1",
        prompt_tokens=[1, 2, 3],
    ))
"""

__version__ = "0.1.0"

# é…ç½®
from .config import (
    SageLLMConfig,
    ModelConfig,
    KVCacheConfig,
    SchedulerConfig,
    BackendConfig,
    BenchmarkConfig,
    InferenceMode,
)

# å¼•æ“
from .engine import (
    SageLLMEngine,
    GenerateRequest,
    GenerateOutput,
)

# å­æ¨¡å—
from . import runtime
from . import kv_runtime
from . import accel
from . import backends
from . import benchmarks

__all__ = [
    # ç‰ˆæœ¬
    "__version__",
    # é…ç½®
    "SageLLMConfig",
    "ModelConfig",
    "KVCacheConfig",
    "SchedulerConfig",
    "BackendConfig",
    "BenchmarkConfig",
    "InferenceMode",
    # å¼•æ“
    "SageLLMEngine",
    "GenerateRequest",
    "GenerateOutput",
    # å­æ¨¡å—
    "runtime",
    "kv_runtime",
    "accel",
    "backends",
    "benchmarks",
]
```

### 5. é›†æˆæµ‹è¯•

åˆ›å»º `tests/integration/test_engine.py`ï¼š

```python
import pytest
from sageLLM import (
    SageLLMEngine, SageLLMConfig, ModelConfig,
    GenerateRequest, KVCacheConfig,
)


class TestEngineIntegration:
    """å¼•æ“é›†æˆæµ‹è¯•"""
    
    @pytest.fixture
    def engine(self):
        """åˆ›å»ºæµ‹è¯•å¼•æ“"""
        config = SageLLMConfig(
            model=ModelConfig(
                model_id="test-model",
                num_layers=2,
                num_heads=2,
                hidden_size=64,
            ),
            kv_cache=KVCacheConfig(
                max_tokens=1024,
                enable_prefix_caching=True,
            ),
        )
        engine = SageLLMEngine(config)
        engine.initialize()
        yield engine
        engine.shutdown()
    
    def test_basic_generate(self, engine):
        """æµ‹è¯•åŸºæœ¬ç”Ÿæˆ"""
        request = GenerateRequest(
            request_id="test_1",
            prompt_tokens=[1, 2, 3],
            max_new_tokens=10,
        )
        
        output = engine.generate(request)
        
        assert output.request_id == "test_1"
        assert len(output.output_tokens) == 10
        assert output.finish_reason == "length"
    
    def test_kv_reuse(self, engine):
        """æµ‹è¯• KV å¤ç”¨"""
        # ç¬¬ä¸€ä¸ªè¯·æ±‚
        request1 = GenerateRequest(
            request_id="req_1",
            prompt_tokens=[1, 2, 3, 4, 5],
            max_new_tokens=5,
        )
        engine.generate(request1)
        
        # ç¬¬äºŒä¸ªè¯·æ±‚ï¼ˆç›¸åŒå‰ç¼€ï¼‰
        request2 = GenerateRequest(
            request_id="req_2",
            prompt_tokens=[1, 2, 3, 4, 5, 6, 7],
            max_new_tokens=5,
        )
        output2 = engine.generate(request2)
        
        assert output2.finish_reason == "length"
        
        # æ£€æŸ¥ KV ç¼“å­˜å‘½ä¸­
        stats = engine.get_stats()
        kv_stats = stats.get("kv_cache", {})
        assert kv_stats.get("cache_hits", 0) > 0
    
    def test_metrics(self, engine):
        """æµ‹è¯•æŒ‡æ ‡æ”¶é›†"""
        request = GenerateRequest(
            request_id="test_metrics",
            prompt_tokens=[1, 2, 3],
            max_new_tokens=20,
        )
        
        output = engine.generate(request)
        
        assert output.metrics is not None
        assert "throughput_tps" in output.metrics
        assert "ttft_ms" in output.metrics
        assert output.metrics["throughput_tps"] > 0


@pytest.mark.asyncio
class TestAsyncEngine:
    """å¼‚æ­¥å¼•æ“æµ‹è¯•"""
    
    @pytest.fixture
    def engine(self):
        config = SageLLMConfig(
            model=ModelConfig(
                model_id="test-model",
                num_layers=2,
                num_heads=2,
                hidden_size=64,
            ),
        )
        engine = SageLLMEngine(config)
        engine.initialize()
        yield engine
        engine.shutdown()
    
    async def test_async_generate(self, engine):
        """æµ‹è¯•å¼‚æ­¥ç”Ÿæˆ"""
        request = GenerateRequest(
            request_id="async_1",
            prompt_tokens=[1, 2, 3],
            max_new_tokens=10,
        )
        
        output = await engine.generate_async(request)
        
        assert output.request_id == "async_1"
        assert len(output.output_tokens) == 10
    
    async def test_streaming(self, engine):
        """æµ‹è¯•æµå¼ç”Ÿæˆ"""
        request = GenerateRequest(
            request_id="stream_1",
            prompt_tokens=[1, 2, 3],
            max_new_tokens=5,
        )
        
        tokens = []
        async for token in engine.generate_stream(request):
            tokens.append(token)
        
        assert len(tokens) == 5
```

---

## éªŒæ”¶æ ‡å‡†

- [ ] å¼•æ“åˆå§‹åŒ–æˆåŠŸï¼Œæ‰€æœ‰ç»„ä»¶æ­£ç¡®åŠ è½½
- [ ] åŸºæœ¬ç”ŸæˆåŠŸèƒ½æ­£å¸¸
- [ ] KV ç¼“å­˜å¤ç”¨æ­£å¸¸å·¥ä½œ
- [ ] æŒ‡æ ‡æ­£ç¡®æ”¶é›†
- [ ] å¼‚æ­¥å’Œæµå¼ API æ­£å¸¸
- [ ] é›†æˆæµ‹è¯•å…¨éƒ¨é€šè¿‡
- [ ] ç¤ºä¾‹ä»£ç å¯è¿è¡Œ

---

## è¾“å‡ºç‰©æ¸…å•

```
sageLLM/
â”œâ”€â”€ __init__.py              # âœ… æ›´æ–°
â”œâ”€â”€ config.py                # âœ… ç»Ÿä¸€é…ç½®
â”œâ”€â”€ engine.py                # âœ… æ¨ç†å¼•æ“
â””â”€â”€ examples/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ basic_inference.py   # âœ… ç¤ºä¾‹

tests/integration/
â””â”€â”€ test_engine.py           # âœ… é›†æˆæµ‹è¯•
```

---

## åç»­å·¥ä½œ

å®Œæˆ Task 6 åï¼Œæ•´ä¸ª sageLLM æ¨¡å—é‡æ„å®Œæˆã€‚åç»­å·¥ä½œï¼š

1. **æ€§èƒ½ä¼˜åŒ–**: å®ç°çœŸæ­£çš„æ¨¡å‹åŠ è½½å’Œæ¨ç†
2. **åˆ†å¸ƒå¼**: æ·»åŠ  TP/PP æ”¯æŒ
3. **æ–‡æ¡£**: å®Œå–„ API æ–‡æ¡£
4. **CI/CD**: æ·»åŠ æ€§èƒ½å›å½’æµ‹è¯•
