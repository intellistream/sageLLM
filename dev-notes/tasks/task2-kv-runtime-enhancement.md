# Task 2: kv_runtime å¤šç²’åº¦ KV ç®¡ç†å¢å¼º

**çŠ¶æ€**: ğŸ”² å¾…å¼€å§‹  
**é¢„è®¡æ—¶é—´**: 4h  
**è¯¾é¢˜å¯¹åº”**: 4.2 é¢å‘å›½äº§èŠ¯ç‰‡çš„ KV æ± åŒ–ä¸ä¸Šä¸‹æ–‡ç¼“å­˜ä¼˜åŒ–  
**å¯å¹¶è¡Œ**: âœ… æ˜¯ï¼ˆä¸ Task 1, 3-5 å¹¶è¡Œï¼‰

---

## èƒŒæ™¯

è¯¾é¢˜ 4.2 è¦æ±‚ï¼š
- "æŒ‰ token æ®µã€æ³¨æ„åŠ›å¤´ç­‰ç²’åº¦çš„å—çº§èµ„æºæ± "
- "HBM/ä¸»å­˜/NVMe ä¸‰çº§å­˜å‚¨"
- "å†·çƒ­ KV è¯†åˆ«æ¨¡å‹å’Œåˆ†å±‚è¿ç§»ç­–ç•¥"
- "è·¨è¯·æ±‚/æ‰¹æ¬¡çš„ KV å¤ç”¨"

æœ¬ä»»åŠ¡åœ¨ç°æœ‰ `kv_runtime` åŸºç¡€ä¸Šè¿›è¡Œå¢å¼ºã€‚

---

## å·¥ä½œç›®å½•

```
/home/shuhao/SAGE/packages/sage-common/src/sage/common/components/sage_llm/sageLLM/kv_runtime/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ protocols.py         # ç°æœ‰ï¼Œå¯èƒ½éœ€è¦æ‰©å±•
â”œâ”€â”€ blocks/              # ğŸ†• å¤šç²’åº¦å—ç®¡ç†
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ multi_granular.py
â”œâ”€â”€ hierarchy/           # ğŸ†• ä¸‰çº§å­˜å‚¨å±‚æ¬¡
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ tiered_storage.py
â”œâ”€â”€ migration/           # ğŸ†• å†·çƒ­è¿ç§»
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ hot_cold.py
â””â”€â”€ reuse/               # ğŸ†• è·¨è¯·æ±‚å¤ç”¨
    â”œâ”€â”€ __init__.py
    â””â”€â”€ cross_request.py
```

---

## å‚è€ƒèµ„æ–™

- vLLM BlockManager: https://github.com/vllm-project/vllm/blob/main/vllm/core/block_manager_v2.py
- Infinite-LLM: https://arxiv.org/abs/2401.02669 (DistKV åˆ†å±‚å­˜å‚¨)
- vLLM Prefix Caching: https://docs.vllm.ai/en/latest/automatic_prefix_caching/apc.html
- PagedAttention: https://arxiv.org/abs/2309.06180

---

## ä»»åŠ¡æ¸…å•

### 1. è®¾è®¡å¤šç²’åº¦ KV å— (`blocks/multi_granular.py`)

```python
from enum import Enum, auto
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Tuple, Any
import time


class KVGranularity(Enum):
    """KV å—ç²’åº¦
    
    ä¼ ç»Ÿæ–¹æ¡ˆåªæœ‰ BLOCK ç²’åº¦ï¼ˆå¦‚ 16 tokensï¼‰ï¼Œ
    æˆ‘ä»¬æ”¯æŒæ›´ç»†ç²’åº¦çš„ç®¡ç†ä»¥æé«˜å¤ç”¨ç‡å’Œå†…å­˜æ•ˆç‡ã€‚
    """
    BLOCK = auto()      # å—çº§ï¼ˆä¼ ç»Ÿï¼Œå¦‚ 16 tokensï¼‰
    TOKEN = auto()      # Token çº§ï¼ˆæœ€ç»†ç²’åº¦ï¼‰
    HEAD = auto()       # æ³¨æ„åŠ›å¤´çº§
    LAYER = auto()      # å±‚çº§ï¼ˆæœ€ç²—ç²’åº¦ï¼‰


class StorageTier(Enum):
    """å­˜å‚¨å±‚çº§"""
    HBM = auto()    # GPU é«˜å¸¦å®½å†…å­˜ï¼ˆæœ€å¿«ï¼Œæœ€è´µï¼‰
    DDR = auto()    # CPU ä¸»å­˜ï¼ˆä¸­ç­‰ï¼‰
    NVME = auto()   # NVMe SSDï¼ˆæœ€æ…¢ï¼Œæœ€ä¾¿å®œï¼‰


@dataclass
class KVBlockDescriptor:
    """KV å—æè¿°ç¬¦
    
    æè¿°ä¸€ä¸ª KV Cache å—çš„å…ƒæ•°æ®ï¼Œä¸åŒ…å«å®é™…æ•°æ®ã€‚
    """
    block_id: int
    granularity: KVGranularity
    
    # ä½ç½®ä¿¡æ¯
    layer_ids: List[int]          # åŒ…å«çš„å±‚ ID
    head_ids: List[int]           # åŒ…å«çš„å¤´ ID
    token_range: Tuple[int, int]  # Token èŒƒå›´ [start, end)
    
    # æ‰€å±ä¿¡æ¯
    sequence_id: int
    request_id: str
    
    # å­˜å‚¨ä½ç½®
    tier: StorageTier = StorageTier.HBM
    device_id: int = 0
    offset: int = 0               # åœ¨å­˜å‚¨ä¸­çš„åç§»
    size_bytes: int = 0
    
    # çŠ¶æ€ä¿¡æ¯
    ref_count: int = 1
    is_shared: bool = False       # æ˜¯å¦è¢«å¤šä¸ªè¯·æ±‚å…±äº«
    
    # è®¿é—®ç»Ÿè®¡ï¼ˆç”¨äºå†·çƒ­è¯†åˆ«ï¼‰
    last_access_time: float = field(default_factory=time.time)
    access_count: int = 0
    access_frequency: float = 0.0  # è®¿é—®é¢‘ç‡ï¼ˆæ¬¡/ç§’ï¼‰
    
    # å…ƒæ•°æ®
    token_hash: Optional[str] = None  # ç”¨äºå‰ç¼€åŒ¹é…
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def update_access(self) -> None:
        """æ›´æ–°è®¿é—®ç»Ÿè®¡"""
        now = time.time()
        elapsed = now - self.last_access_time
        if elapsed > 0:
            self.access_frequency = self.access_count / elapsed
        self.last_access_time = now
        self.access_count += 1


@dataclass
class KVPoolConfig:
    """KV æ± é…ç½®"""
    # å®¹é‡é…ç½®
    hbm_capacity_bytes: int = 16 * 1024**3    # 16 GB
    ddr_capacity_bytes: int = 64 * 1024**3    # 64 GB
    nvme_capacity_bytes: int = 256 * 1024**3  # 256 GB
    
    # å—é…ç½®
    block_size: int = 16          # tokens per block
    default_granularity: KVGranularity = KVGranularity.BLOCK
    
    # è¡Œä¸ºé…ç½®
    enable_sharing: bool = True   # å…è®¸è·¨è¯·æ±‚å…±äº«
    enable_tiering: bool = True   # å¯ç”¨åˆ†å±‚å­˜å‚¨


class MultiGranularKVPool:
    """å¤šç²’åº¦ KV æ± 
    
    æ”¯æŒä¸åŒç²’åº¦çš„ KV Cache ç®¡ç†ï¼š
    - BLOCK: ä¼ ç»Ÿå—çº§ï¼Œé€‚åˆæ‰¹é‡æ“ä½œ
    - TOKEN: Token çº§ï¼Œé€‚åˆç»†ç²’åº¦å¤ç”¨
    - HEAD: å¤´çº§ï¼Œé€‚åˆ MQA/GQA ä¼˜åŒ–
    - LAYER: å±‚çº§ï¼Œé€‚åˆ early exit
    """
    
    def __init__(self, config: KVPoolConfig):
        self.config = config
        
        # å—ç´¢å¼•
        self._blocks: Dict[int, KVBlockDescriptor] = {}
        self._next_block_id = 0
        
        # æŒ‰åºåˆ—ç´¢å¼•
        self._sequence_blocks: Dict[int, List[int]] = {}
        
        # æŒ‰å±‚çº§ç´¢å¼•ï¼ˆç”¨äºå¿«é€ŸæŸ¥æ‰¾ï¼‰
        self._tier_blocks: Dict[StorageTier, List[int]] = {
            tier: [] for tier in StorageTier
        }
        
        # ç©ºé—²åˆ—è¡¨
        self._free_blocks: Dict[StorageTier, List[int]] = {
            tier: [] for tier in StorageTier
        }
        
        # ç»Ÿè®¡
        self._stats = {
            "total_allocations": 0,
            "total_deallocations": 0,
            "total_migrations": 0,
            "cache_hits": 0,
            "cache_misses": 0,
        }
    
    def allocate(
        self,
        sequence_id: int,
        request_id: str,
        num_tokens: int,
        layer_ids: List[int],
        head_ids: Optional[List[int]] = None,
        granularity: Optional[KVGranularity] = None,
        preferred_tier: StorageTier = StorageTier.HBM,
    ) -> List[KVBlockDescriptor]:
        """åˆ†é… KV å—
        
        Args:
            sequence_id: åºåˆ— ID
            request_id: è¯·æ±‚ ID
            num_tokens: éœ€è¦çš„ token æ•°
            layer_ids: å±‚ ID åˆ—è¡¨
            head_ids: å¤´ ID åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œç”¨äºç»†ç²’åº¦åˆ†é…ï¼‰
            granularity: ç²’åº¦ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
            preferred_tier: é¦–é€‰å­˜å‚¨å±‚
            
        Returns:
            åˆ†é…çš„ KV å—æè¿°ç¬¦åˆ—è¡¨
        """
        granularity = granularity or self.config.default_granularity
        
        # è®¡ç®—éœ€è¦çš„å—æ•°
        if granularity == KVGranularity.BLOCK:
            num_blocks = (num_tokens + self.config.block_size - 1) // self.config.block_size
        elif granularity == KVGranularity.TOKEN:
            num_blocks = num_tokens
        else:
            num_blocks = 1  # HEAD/LAYER ç²’åº¦
        
        # åˆ†é…å—
        allocated = []
        for i in range(num_blocks):
            block = self._allocate_single_block(
                sequence_id=sequence_id,
                request_id=request_id,
                granularity=granularity,
                layer_ids=layer_ids,
                head_ids=head_ids or [],
                token_start=i * self.config.block_size,
                token_end=min((i + 1) * self.config.block_size, num_tokens),
                tier=preferred_tier,
            )
            allocated.append(block)
        
        self._stats["total_allocations"] += len(allocated)
        return allocated
    
    def _allocate_single_block(
        self,
        sequence_id: int,
        request_id: str,
        granularity: KVGranularity,
        layer_ids: List[int],
        head_ids: List[int],
        token_start: int,
        token_end: int,
        tier: StorageTier,
    ) -> KVBlockDescriptor:
        """åˆ†é…å•ä¸ªå—"""
        block_id = self._next_block_id
        self._next_block_id += 1
        
        block = KVBlockDescriptor(
            block_id=block_id,
            granularity=granularity,
            layer_ids=layer_ids,
            head_ids=head_ids,
            token_range=(token_start, token_end),
            sequence_id=sequence_id,
            request_id=request_id,
            tier=tier,
        )
        
        # æ³¨å†Œå—
        self._blocks[block_id] = block
        self._tier_blocks[tier].append(block_id)
        
        if sequence_id not in self._sequence_blocks:
            self._sequence_blocks[sequence_id] = []
        self._sequence_blocks[sequence_id].append(block_id)
        
        return block
    
    def deallocate(self, blocks: List[KVBlockDescriptor]) -> None:
        """é‡Šæ”¾ KV å—"""
        for block in blocks:
            if block.ref_count > 1:
                block.ref_count -= 1
            else:
                self._free_block(block)
        
        self._stats["total_deallocations"] += len(blocks)
    
    def _free_block(self, block: KVBlockDescriptor) -> None:
        """é‡Šæ”¾å•ä¸ªå—"""
        block_id = block.block_id
        
        # ä»ç´¢å¼•ç§»é™¤
        if block_id in self._blocks:
            del self._blocks[block_id]
        
        if block.sequence_id in self._sequence_blocks:
            if block_id in self._sequence_blocks[block.sequence_id]:
                self._sequence_blocks[block.sequence_id].remove(block_id)
        
        if block_id in self._tier_blocks[block.tier]:
            self._tier_blocks[block.tier].remove(block_id)
        
        # åŠ å…¥ç©ºé—²åˆ—è¡¨
        self._free_blocks[block.tier].append(block_id)
    
    def get_blocks_by_sequence(self, sequence_id: int) -> List[KVBlockDescriptor]:
        """è·å–åºåˆ—çš„æ‰€æœ‰å—"""
        block_ids = self._sequence_blocks.get(sequence_id, [])
        return [self._blocks[bid] for bid in block_ids if bid in self._blocks]
    
    def query_by_prefix(
        self,
        token_ids: List[int],
        min_match_length: int = 1,
    ) -> Optional[List[KVBlockDescriptor]]:
        """æ ¹æ®å‰ç¼€æŸ¥è¯¢å¯å¤ç”¨çš„ KV å—
        
        Args:
            token_ids: Token åºåˆ—
            min_match_length: æœ€å°åŒ¹é…é•¿åº¦
            
        Returns:
            åŒ¹é…çš„ KV å—åˆ—è¡¨ï¼Œå¦‚æœæ²¡æœ‰åŒ¹é…è¿”å› None
        """
        # è¿™é‡Œéœ€è¦ä¸ prefix_reuse æ¨¡å—é›†æˆ
        # ç®€åŒ–å®ç°ï¼šéå†æ‰€æœ‰å—æ‰¾å‰ç¼€åŒ¹é…
        ...
        return None
    
    def get_tier_usage(self, tier: StorageTier) -> Dict[str, Any]:
        """è·å–å­˜å‚¨å±‚ä½¿ç”¨æƒ…å†µ"""
        blocks = self._tier_blocks[tier]
        total_bytes = sum(
            self._blocks[bid].size_bytes 
            for bid in blocks 
            if bid in self._blocks
        )
        
        capacity = {
            StorageTier.HBM: self.config.hbm_capacity_bytes,
            StorageTier.DDR: self.config.ddr_capacity_bytes,
            StorageTier.NVME: self.config.nvme_capacity_bytes,
        }[tier]
        
        return {
            "tier": tier.name,
            "num_blocks": len(blocks),
            "used_bytes": total_bytes,
            "capacity_bytes": capacity,
            "utilization": total_bytes / capacity if capacity > 0 else 0,
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–æ± ç»Ÿè®¡"""
        return {
            **self._stats,
            "total_blocks": len(self._blocks),
            "hbm_usage": self.get_tier_usage(StorageTier.HBM),
            "ddr_usage": self.get_tier_usage(StorageTier.DDR),
            "nvme_usage": self.get_tier_usage(StorageTier.NVME),
        }
```

### 2. å®ç°ä¸‰çº§å­˜å‚¨å±‚æ¬¡ (`hierarchy/tiered_storage.py`)

```python
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Dict, List, Optional, Any
import torch

from ..blocks.multi_granular import StorageTier, KVBlockDescriptor


@dataclass
class TierConfig:
    """å­˜å‚¨å±‚é…ç½®"""
    tier: StorageTier
    capacity_bytes: int
    bandwidth_gbps: float     # å¸¦å®½ï¼ˆGB/sï¼‰
    latency_us: float         # å»¶è¿Ÿï¼ˆå¾®ç§’ï¼‰
    
    # å¯é€‰ï¼šè®¾å¤‡ç‰¹å®šé…ç½®
    device_id: Optional[int] = None
    path: Optional[str] = None  # NVMe è·¯å¾„


@dataclass
class TierUsage:
    """å­˜å‚¨å±‚ä½¿ç”¨æƒ…å†µ"""
    tier: StorageTier
    used_bytes: int
    free_bytes: int
    capacity_bytes: int
    num_blocks: int
    
    @property
    def utilization(self) -> float:
        if self.capacity_bytes == 0:
            return 0.0
        return self.used_bytes / self.capacity_bytes


class StorageBackend(ABC):
    """å­˜å‚¨åç«¯æŠ½è±¡"""
    
    @abstractmethod
    def read(self, offset: int, size: int) -> torch.Tensor:
        """è¯»å–æ•°æ®"""
        ...
    
    @abstractmethod
    def write(self, offset: int, data: torch.Tensor) -> None:
        """å†™å…¥æ•°æ®"""
        ...
    
    @abstractmethod
    def get_free_space(self) -> int:
        """è·å–ç©ºé—²ç©ºé—´"""
        ...


class HBMBackend(StorageBackend):
    """HBMï¼ˆGPU æ˜¾å­˜ï¼‰åç«¯"""
    
    def __init__(self, device_id: int, capacity_bytes: int):
        self.device_id = device_id
        self.capacity_bytes = capacity_bytes
        self.device = torch.device(f"cuda:{device_id}")
        
        # é¢„åˆ†é…æ˜¾å­˜æ± 
        self._pool: Optional[torch.Tensor] = None
        self._allocated = 0
    
    def initialize(self) -> None:
        """åˆå§‹åŒ–æ˜¾å­˜æ± """
        self._pool = torch.empty(
            self.capacity_bytes,
            dtype=torch.uint8,
            device=self.device,
        )
    
    def read(self, offset: int, size: int) -> torch.Tensor:
        if self._pool is None:
            raise RuntimeError("HBM backend not initialized")
        return self._pool[offset:offset + size].clone()
    
    def write(self, offset: int, data: torch.Tensor) -> None:
        if self._pool is None:
            raise RuntimeError("HBM backend not initialized")
        self._pool[offset:offset + len(data)] = data.to(self.device).view(-1)
    
    def get_free_space(self) -> int:
        return self.capacity_bytes - self._allocated


class DDRBackend(StorageBackend):
    """DDRï¼ˆCPU ä¸»å­˜ï¼‰åç«¯"""
    
    def __init__(self, capacity_bytes: int):
        self.capacity_bytes = capacity_bytes
        self._pool: Optional[torch.Tensor] = None
        self._allocated = 0
    
    def initialize(self) -> None:
        """åˆå§‹åŒ–å†…å­˜æ± """
        self._pool = torch.empty(
            self.capacity_bytes,
            dtype=torch.uint8,
            pin_memory=True,  # é”é¡µå†…å­˜ï¼ŒåŠ é€Ÿ GPU ä¼ è¾“
        )
    
    def read(self, offset: int, size: int) -> torch.Tensor:
        if self._pool is None:
            raise RuntimeError("DDR backend not initialized")
        return self._pool[offset:offset + size].clone()
    
    def write(self, offset: int, data: torch.Tensor) -> None:
        if self._pool is None:
            raise RuntimeError("DDR backend not initialized")
        self._pool[offset:offset + len(data)] = data.cpu().view(-1)
    
    def get_free_space(self) -> int:
        return self.capacity_bytes - self._allocated


class NVMeBackend(StorageBackend):
    """NVMe SSD åç«¯"""
    
    def __init__(self, path: str, capacity_bytes: int):
        self.path = path
        self.capacity_bytes = capacity_bytes
        self._file = None
        self._allocated = 0
    
    def initialize(self) -> None:
        """åˆå§‹åŒ–æ–‡ä»¶"""
        import os
        os.makedirs(os.path.dirname(self.path), exist_ok=True)
        self._file = open(self.path, "wb+")
        # é¢„åˆ†é…æ–‡ä»¶
        self._file.truncate(self.capacity_bytes)
    
    def read(self, offset: int, size: int) -> torch.Tensor:
        if self._file is None:
            raise RuntimeError("NVMe backend not initialized")
        self._file.seek(offset)
        data = self._file.read(size)
        return torch.frombuffer(data, dtype=torch.uint8).clone()
    
    def write(self, offset: int, data: torch.Tensor) -> None:
        if self._file is None:
            raise RuntimeError("NVMe backend not initialized")
        self._file.seek(offset)
        self._file.write(data.cpu().numpy().tobytes())
    
    def get_free_space(self) -> int:
        return self.capacity_bytes - self._allocated
    
    def close(self) -> None:
        if self._file:
            self._file.close()


class TieredKVStorage:
    """ä¸‰çº§ KV å­˜å‚¨ç®¡ç†å™¨
    
    ç®¡ç† HBM -> DDR -> NVMe ä¸‰çº§å­˜å‚¨ï¼š
    - HBM: çƒ­æ•°æ®ï¼Œé«˜é€Ÿè®¿é—®
    - DDR: æ¸©æ•°æ®ï¼ŒCPU é”é¡µå†…å­˜
    - NVMe: å†·æ•°æ®ï¼ŒæŒä¹…åŒ–å­˜å‚¨
    """
    
    def __init__(
        self,
        hbm_config: TierConfig,
        ddr_config: TierConfig,
        nvme_config: Optional[TierConfig] = None,
    ):
        self.configs = {
            StorageTier.HBM: hbm_config,
            StorageTier.DDR: ddr_config,
        }
        if nvme_config:
            self.configs[StorageTier.NVME] = nvme_config
        
        # åˆå§‹åŒ–åç«¯
        self.backends: Dict[StorageTier, StorageBackend] = {}
        self._init_backends()
        
        # å—ä½ç½®æ˜ å°„
        self._block_locations: Dict[int, tuple] = {}  # block_id -> (tier, offset)
    
    def _init_backends(self) -> None:
        """åˆå§‹åŒ–å­˜å‚¨åç«¯"""
        hbm_cfg = self.configs[StorageTier.HBM]
        self.backends[StorageTier.HBM] = HBMBackend(
            device_id=hbm_cfg.device_id or 0,
            capacity_bytes=hbm_cfg.capacity_bytes,
        )
        
        ddr_cfg = self.configs[StorageTier.DDR]
        self.backends[StorageTier.DDR] = DDRBackend(
            capacity_bytes=ddr_cfg.capacity_bytes,
        )
        
        if StorageTier.NVME in self.configs:
            nvme_cfg = self.configs[StorageTier.NVME]
            self.backends[StorageTier.NVME] = NVMeBackend(
                path=nvme_cfg.path or "/tmp/sagellm_kv_cache.bin",
                capacity_bytes=nvme_cfg.capacity_bytes,
            )
        
        # åˆå§‹åŒ–æ‰€æœ‰åç«¯
        for backend in self.backends.values():
            backend.initialize()
    
    def get_tier_usage(self, tier: StorageTier) -> TierUsage:
        """è·å–å­˜å‚¨å±‚ä½¿ç”¨æƒ…å†µ"""
        if tier not in self.backends:
            raise ValueError(f"Tier {tier} not configured")
        
        backend = self.backends[tier]
        config = self.configs[tier]
        free = backend.get_free_space()
        
        return TierUsage(
            tier=tier,
            used_bytes=config.capacity_bytes - free,
            free_bytes=free,
            capacity_bytes=config.capacity_bytes,
            num_blocks=sum(
                1 for loc in self._block_locations.values() 
                if loc[0] == tier
            ),
        )
    
    def read_blocks(
        self,
        blocks: List[KVBlockDescriptor],
        target_tier: StorageTier = StorageTier.HBM,
    ) -> torch.Tensor:
        """è¯»å– KV å—åˆ°ç›®æ ‡å±‚
        
        å¦‚æœå—ä¸åœ¨ç›®æ ‡å±‚ï¼Œä¼šè‡ªåŠ¨è¿ç§»ã€‚
        
        Args:
            blocks: è¦è¯»å–çš„å—
            target_tier: ç›®æ ‡å­˜å‚¨å±‚
            
        Returns:
            æ‹¼æ¥åçš„ KV æ•°æ®å¼ é‡
        """
        data_list = []
        
        for block in blocks:
            if block.block_id not in self._block_locations:
                raise ValueError(f"Block {block.block_id} not found in storage")
            
            current_tier, offset = self._block_locations[block.block_id]
            
            # è¯»å–æ•°æ®
            data = self.backends[current_tier].read(offset, block.size_bytes)
            
            # å¦‚æœéœ€è¦è¿ç§»åˆ°å…¶ä»–å±‚
            if current_tier != target_tier:
                # è¿ç§»ï¼ˆç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥å¼‚æ­¥ï¼‰
                self._migrate_block(block, current_tier, target_tier)
            
            # è½¬ç§»åˆ°ç›®æ ‡è®¾å¤‡
            if target_tier == StorageTier.HBM:
                device_id = self.configs[StorageTier.HBM].device_id or 0
                data = data.to(f"cuda:{device_id}")
            
            data_list.append(data)
            block.update_access()
        
        return torch.cat(data_list) if data_list else torch.tensor([])
    
    def write_blocks(
        self,
        data: torch.Tensor,
        blocks: List[KVBlockDescriptor],
    ) -> None:
        """å†™å…¥ KV æ•°æ®
        
        Args:
            data: KV æ•°æ®å¼ é‡
            blocks: å—æè¿°ç¬¦åˆ—è¡¨
        """
        offset = 0
        for block in blocks:
            block_data = data[offset:offset + block.size_bytes]
            tier = block.tier
            
            # åˆ†é…å­˜å‚¨ä½ç½®
            backend = self.backends[tier]
            storage_offset = self._allocate_space(tier, block.size_bytes)
            
            # å†™å…¥
            backend.write(storage_offset, block_data)
            
            # è®°å½•ä½ç½®
            self._block_locations[block.block_id] = (tier, storage_offset)
            
            offset += block.size_bytes
    
    def _allocate_space(self, tier: StorageTier, size: int) -> int:
        """åœ¨æŒ‡å®šå±‚åˆ†é…ç©ºé—´ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        # å®é™…å®ç°éœ€è¦æ›´å¤æ‚çš„ç©ºé—´ç®¡ç†
        backend = self.backends[tier]
        free = backend.get_free_space()
        if size > free:
            raise MemoryError(f"Not enough space in {tier.name}")
        
        # ç®€åŒ–ï¼šé¡ºåºåˆ†é…
        offset = self.configs[tier].capacity_bytes - free
        return offset
    
    def _migrate_block(
        self,
        block: KVBlockDescriptor,
        from_tier: StorageTier,
        to_tier: StorageTier,
    ) -> None:
        """è¿ç§»å—åˆ°å¦ä¸€å±‚"""
        if from_tier == to_tier:
            return
        
        # è¯»å–
        _, offset = self._block_locations[block.block_id]
        data = self.backends[from_tier].read(offset, block.size_bytes)
        
        # å†™å…¥æ–°ä½ç½®
        new_offset = self._allocate_space(to_tier, block.size_bytes)
        self.backends[to_tier].write(new_offset, data)
        
        # æ›´æ–°ä½ç½®è®°å½•
        self._block_locations[block.block_id] = (to_tier, new_offset)
        block.tier = to_tier
    
    def get_estimated_latency(
        self,
        tier: StorageTier,
        size_bytes: int,
    ) -> float:
        """ä¼°ç®—è®¿é—®å»¶è¿Ÿï¼ˆå¾®ç§’ï¼‰"""
        config = self.configs[tier]
        # å»¶è¿Ÿ + ä¼ è¾“æ—¶é—´
        transfer_time_us = (size_bytes / (config.bandwidth_gbps * 1e9)) * 1e6
        return config.latency_us + transfer_time_us
```

### 3. å®ç°å†·çƒ­è¯†åˆ«ä¸è¿ç§» (`migration/hot_cold.py`)

```python
from dataclasses import dataclass
from typing import List, Dict, Literal, Optional
import time

from ..blocks.multi_granular import KVBlockDescriptor, StorageTier
from ..hierarchy.tiered_storage import TieredKVStorage


@dataclass
class MigrationPlan:
    """è¿ç§»è®¡åˆ’"""
    block_id: int
    from_tier: StorageTier
    to_tier: StorageTier
    priority: int = 0
    deadline_ms: Optional[float] = None


@dataclass
class MigrationResult:
    """è¿ç§»ç»“æœ"""
    success: bool
    block_id: int
    from_tier: StorageTier
    to_tier: StorageTier
    duration_ms: float
    size_bytes: int


class HotColdClassifier:
    """KV å—å†·çƒ­åˆ†ç±»å™¨
    
    åŸºäºè®¿é—®é¢‘ç‡å’Œæœ€è¿‘è®¿é—®æ—¶é—´åˆ¤æ–­å—çš„å†·çƒ­ç¨‹åº¦ï¼š
    - hot: é¢‘ç¹è®¿é—®ï¼Œåº”ä¿ç•™åœ¨ HBM
    - warm: ä¸­ç­‰è®¿é—®ï¼Œå¯ä»¥åœ¨ DDR
    - cold: å¾ˆå°‘è®¿é—®ï¼Œå¯ä»¥è¿ç§»åˆ° NVMe
    """
    
    def __init__(
        self,
        hot_frequency_threshold: float = 1.0,    # è®¿é—®é¢‘ç‡ > 1æ¬¡/ç§’ä¸º hot
        cold_timeout_s: float = 60.0,            # 60ç§’æœªè®¿é—®ä¸º cold
        warm_frequency_threshold: float = 0.1,   # è®¿é—®é¢‘ç‡ < 0.1æ¬¡/ç§’ä¸º cold
    ):
        self.hot_frequency_threshold = hot_frequency_threshold
        self.cold_timeout_s = cold_timeout_s
        self.warm_frequency_threshold = warm_frequency_threshold
    
    def classify(
        self,
        block: KVBlockDescriptor,
    ) -> Literal["hot", "warm", "cold"]:
        """åˆ†ç±» KV å—
        
        Args:
            block: KV å—æè¿°ç¬¦
            
        Returns:
            "hot", "warm", æˆ– "cold"
        """
        now = time.time()
        time_since_access = now - block.last_access_time
        
        # æ ¹æ®è®¿é—®é¢‘ç‡åˆ¤æ–­
        if block.access_frequency >= self.hot_frequency_threshold:
            return "hot"
        
        # æ ¹æ®æœ€è¿‘è®¿é—®æ—¶é—´åˆ¤æ–­
        if time_since_access > self.cold_timeout_s:
            return "cold"
        
        # æ ¹æ®ä½é¢‘ç‡åˆ¤æ–­
        if block.access_frequency < self.warm_frequency_threshold:
            return "cold"
        
        return "warm"
    
    def predict_lifetime(self, block: KVBlockDescriptor) -> float:
        """é¢„æµ‹ KV å—å‰©ä½™ç”Ÿå‘½å‘¨æœŸï¼ˆç§’ï¼‰
        
        åŸºäºè®¿é—®æ¨¡å¼é¢„æµ‹å—è¿˜ä¼šè¢«ä½¿ç”¨å¤šä¹…ã€‚
        ç”¨äºå†³å®šæ˜¯å¦å€¼å¾—è¿ç§»ã€‚
        """
        # ç®€åŒ–å®ç°ï¼šåŸºäºè®¿é—®é¢‘ç‡ä¼°ç®—
        if block.access_frequency > 0:
            # å‡è®¾è®¿é—®ä¼šæŒç»­ï¼Œé¢„æµ‹ä¸ºå½“å‰é¢‘ç‡çš„å€’æ•°çš„ 10 å€
            return min(10.0 / block.access_frequency, 3600.0)
        else:
            # æ— è®¿é—®å†å²ï¼Œå‡è®¾çŸ­æœŸå†…ä¸ä¼šå†è®¿é—®
            return 0.0
    
    def get_priority_score(self, block: KVBlockDescriptor) -> float:
        """è®¡ç®—è¿ç§»ä¼˜å…ˆçº§åˆ†æ•°
        
        åˆ†æ•°è¶Šé«˜ï¼Œè¶Šåº”è¯¥è¢«è¿ç§»åˆ°æ›´ä½å±‚çº§ã€‚
        """
        classification = self.classify(block)
        base_score = {"hot": 0.0, "warm": 0.5, "cold": 1.0}[classification]
        
        # è°ƒæ•´å› ç´ 
        time_since_access = time.time() - block.last_access_time
        time_factor = min(time_since_access / self.cold_timeout_s, 1.0)
        
        frequency_factor = 1.0 - min(block.access_frequency / self.hot_frequency_threshold, 1.0)
        
        return base_score * 0.4 + time_factor * 0.3 + frequency_factor * 0.3


class KVMigrator:
    """KV å—è¿ç§»å™¨
    
    è´Ÿè´£åœ¨å­˜å‚¨å±‚ä¹‹é—´è¿ç§» KV å—ï¼š
    - æ ¹æ®å†·çƒ­åˆ†ç±»è‡ªåŠ¨è¿ç§»
    - æ”¯æŒæ‰¹é‡è¿ç§»
    - æ”¯æŒä¸è®¡ç®—é‡å 
    """
    
    def __init__(
        self,
        storage: TieredKVStorage,
        classifier: HotColdClassifier,
    ):
        self.storage = storage
        self.classifier = classifier
        
        # ç»Ÿè®¡
        self._stats = {
            "total_migrations": 0,
            "hbm_to_ddr": 0,
            "ddr_to_nvme": 0,
            "ddr_to_hbm": 0,
            "nvme_to_ddr": 0,
            "total_bytes_migrated": 0,
        }
    
    def plan_migration(
        self,
        blocks: List[KVBlockDescriptor],
        pressure: Dict[StorageTier, float],
    ) -> List[MigrationPlan]:
        """è§„åˆ’è¿ç§»
        
        Args:
            blocks: æ‰€æœ‰ KV å—
            pressure: å„å±‚å‹åŠ› (0.0-1.0)ï¼Œé«˜å‹åŠ›å±‚éœ€è¦è…¾å‡ºç©ºé—´
            
        Returns:
            è¿ç§»è®¡åˆ’åˆ—è¡¨
        """
        plans = []
        
        # 1. å¤„ç†é«˜å‹åŠ›å±‚ï¼šå‘ä¸‹è¿ç§» cold å—
        for tier, p in pressure.items():
            if p > 0.9:  # 90% ä»¥ä¸Šéœ€è¦è¿ç§»
                tier_blocks = [b for b in blocks if b.tier == tier]
                
                # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆé«˜åˆ† = æ›´åº”è¯¥è¿ç§»ï¼‰
                tier_blocks.sort(
                    key=lambda b: self.classifier.get_priority_score(b),
                    reverse=True,
                )
                
                # é€‰æ‹©è¦è¿ç§»çš„å—
                target_tier = self._get_lower_tier(tier)
                if target_tier is None:
                    continue
                
                # è¿ç§»è¶³å¤Ÿçš„å—é™åˆ° 80%
                bytes_to_free = int((p - 0.8) * self.storage.configs[tier].capacity_bytes)
                bytes_planned = 0
                
                for block in tier_blocks:
                    if bytes_planned >= bytes_to_free:
                        break
                    
                    classification = self.classifier.classify(block)
                    if classification in ("cold", "warm"):
                        plans.append(MigrationPlan(
                            block_id=block.block_id,
                            from_tier=tier,
                            to_tier=target_tier,
                            priority=int(self.classifier.get_priority_score(block) * 100),
                        ))
                        bytes_planned += block.size_bytes
        
        # 2. å¤„ç†ä½å‹åŠ›å±‚ï¼šå‘ä¸Šè¿ç§» hot å—
        for tier, p in pressure.items():
            if p < 0.5:  # 50% ä»¥ä¸‹æœ‰ç©ºé—´
                higher_tier = self._get_higher_tier(tier)
                if higher_tier is None:
                    continue
                
                higher_blocks = [b for b in blocks if b.tier == higher_tier]
                for block in higher_blocks:
                    if self.classifier.classify(block) == "hot":
                        plans.append(MigrationPlan(
                            block_id=block.block_id,
                            from_tier=higher_tier,
                            to_tier=tier,
                            priority=90,  # Hot å—é«˜ä¼˜å…ˆçº§
                        ))
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        plans.sort(key=lambda p: p.priority, reverse=True)
        return plans
    
    def _get_lower_tier(self, tier: StorageTier) -> Optional[StorageTier]:
        """è·å–æ›´ä½å±‚çº§"""
        if tier == StorageTier.HBM:
            return StorageTier.DDR
        elif tier == StorageTier.DDR:
            if StorageTier.NVME in self.storage.backends:
                return StorageTier.NVME
        return None
    
    def _get_higher_tier(self, tier: StorageTier) -> Optional[StorageTier]:
        """è·å–æ›´é«˜å±‚çº§"""
        if tier == StorageTier.NVME:
            return StorageTier.DDR
        elif tier == StorageTier.DDR:
            return StorageTier.HBM
        return None
    
    def execute_migration(
        self,
        plan: MigrationPlan,
        block: KVBlockDescriptor,
    ) -> MigrationResult:
        """æ‰§è¡Œå•ä¸ªè¿ç§»
        
        Args:
            plan: è¿ç§»è®¡åˆ’
            block: KV å—æè¿°ç¬¦
            
        Returns:
            è¿ç§»ç»“æœ
        """
        start_time = time.time()
        
        try:
            self.storage._migrate_block(block, plan.from_tier, plan.to_tier)
            success = True
        except Exception:
            success = False
        
        duration_ms = (time.time() - start_time) * 1000
        
        # æ›´æ–°ç»Ÿè®¡
        if success:
            self._stats["total_migrations"] += 1
            self._stats["total_bytes_migrated"] += block.size_bytes
            
            key = f"{plan.from_tier.name.lower()}_to_{plan.to_tier.name.lower()}"
            if key in self._stats:
                self._stats[key] += 1
        
        return MigrationResult(
            success=success,
            block_id=plan.block_id,
            from_tier=plan.from_tier,
            to_tier=plan.to_tier,
            duration_ms=duration_ms,
            size_bytes=block.size_bytes,
        )
    
    async def execute_migration_async(
        self,
        plans: List[MigrationPlan],
        blocks: Dict[int, KVBlockDescriptor],
        overlap_compute: bool = True,
    ) -> List[MigrationResult]:
        """å¼‚æ­¥æ‰¹é‡æ‰§è¡Œè¿ç§»
        
        Args:
            plans: è¿ç§»è®¡åˆ’åˆ—è¡¨
            blocks: å— ID åˆ°æè¿°ç¬¦çš„æ˜ å°„
            overlap_compute: æ˜¯å¦ä¸è®¡ç®—é‡å 
            
        Returns:
            è¿ç§»ç»“æœåˆ—è¡¨
        """
        results = []
        for plan in plans:
            block = blocks.get(plan.block_id)
            if block:
                result = self.execute_migration(plan, block)
                results.append(result)
        return results
    
    def get_stats(self) -> Dict:
        """è·å–è¿ç§»ç»Ÿè®¡"""
        return self._stats.copy()
```

### 4. å®ç°è·¨è¯·æ±‚ KV å¤ç”¨ (`reuse/cross_request.py`)

```python
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Any
import hashlib

from ..blocks.multi_granular import MultiGranularKVPool, KVBlockDescriptor


@dataclass
class ReuseResult:
    """å¤ç”¨ç»“æœ"""
    reused: bool
    matched_blocks: List[KVBlockDescriptor]
    matched_tokens: int
    total_tokens: int
    
    @property
    def reuse_ratio(self) -> float:
        if self.total_tokens == 0:
            return 0.0
        return self.matched_tokens / self.total_tokens


@dataclass
class PrefixEntry:
    """å‰ç¼€ç´¢å¼•æ¡ç›®"""
    token_hash: str
    token_ids: List[int]
    block_ids: List[int]
    ref_count: int = 1
    tenant_id: Optional[str] = None


class CrossRequestKVCache:
    """è·¨è¯·æ±‚ KV ç¼“å­˜
    
    æ”¯æŒï¼š
    1. ç›¸åŒ prefix çš„ KV å¤ç”¨
    2. å¤šç§Ÿæˆ·éš”ç¦»
    3. å¼•ç”¨è®¡æ•°ç®¡ç†
    
    ä¸ prefix_reuse æ¨¡å—é›†æˆï¼Œæä¾›æ›´é«˜å±‚çš„å¤ç”¨æ¥å£ã€‚
    """
    
    def __init__(
        self,
        pool: MultiGranularKVPool,
        enable_tenant_isolation: bool = False,
    ):
        self.pool = pool
        self.enable_tenant_isolation = enable_tenant_isolation
        
        # å‰ç¼€ç´¢å¼•ï¼šhash -> PrefixEntry
        self._prefix_index: Dict[str, PrefixEntry] = {}
        
        # Token åºåˆ—åˆ° hash çš„æ˜ å°„ï¼ˆåŠ é€ŸæŸ¥æ‰¾ï¼‰
        self._token_to_hash: Dict[tuple, str] = {}
        
        # ç»Ÿè®¡
        self._stats = {
            "total_queries": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "total_reused_tokens": 0,
        }
    
    def _compute_hash(self, token_ids: List[int]) -> str:
        """è®¡ç®— token åºåˆ—çš„ hash"""
        key = ",".join(map(str, token_ids))
        return hashlib.sha256(key.encode()).hexdigest()[:16]
    
    def try_reuse(
        self,
        request_id: str,
        token_ids: List[int],
        tenant_id: Optional[str] = None,
    ) -> ReuseResult:
        """å°è¯•å¤ç”¨å·²æœ‰ KV
        
        Args:
            request_id: è¯·æ±‚ ID
            token_ids: Token åºåˆ—
            tenant_id: ç§Ÿæˆ· IDï¼ˆç”¨äºéš”ç¦»ï¼‰
            
        Returns:
            å¤ç”¨ç»“æœ
        """
        self._stats["total_queries"] += 1
        
        # å°è¯•æ‰¾æœ€é•¿åŒ¹é…å‰ç¼€
        best_match = None
        best_length = 0
        
        # ä»é•¿åˆ°çŸ­å°è¯•åŒ¹é…
        for length in range(len(token_ids), 0, -1):
            prefix = token_ids[:length]
            prefix_tuple = tuple(prefix)
            
            # æ£€æŸ¥ç¼“å­˜
            if prefix_tuple in self._token_to_hash:
                hash_key = self._token_to_hash[prefix_tuple]
                entry = self._prefix_index.get(hash_key)
                
                if entry:
                    # æ£€æŸ¥ç§Ÿæˆ·éš”ç¦»
                    if self.enable_tenant_isolation and entry.tenant_id != tenant_id:
                        continue
                    
                    best_match = entry
                    best_length = length
                    break
        
        if best_match is None:
            self._stats["cache_misses"] += 1
            return ReuseResult(
                reused=False,
                matched_blocks=[],
                matched_tokens=0,
                total_tokens=len(token_ids),
            )
        
        # æ‰¾åˆ°åŒ¹é…
        self._stats["cache_hits"] += 1
        self._stats["total_reused_tokens"] += best_length
        
        # å¢åŠ å¼•ç”¨è®¡æ•°
        best_match.ref_count += 1
        
        # è·å–å¯¹åº”çš„ KV å—
        matched_blocks = [
            self.pool._blocks[bid]
            for bid in best_match.block_ids
            if bid in self.pool._blocks
        ]
        
        return ReuseResult(
            reused=True,
            matched_blocks=matched_blocks,
            matched_tokens=best_length,
            total_tokens=len(token_ids),
        )
    
    def commit(
        self,
        request_id: str,
        token_ids: List[int],
        blocks: List[KVBlockDescriptor],
        shareable: bool = True,
        tenant_id: Optional[str] = None,
    ) -> None:
        """æäº¤æ–° KV ä¾›åç»­å¤ç”¨
        
        Args:
            request_id: è¯·æ±‚ ID
            token_ids: Token åºåˆ—
            blocks: KV å—åˆ—è¡¨
            shareable: æ˜¯å¦å¯å…±äº«
            tenant_id: ç§Ÿæˆ· ID
        """
        if not shareable:
            return
        
        # è®¡ç®— hash
        hash_key = self._compute_hash(token_ids)
        
        # åˆ›å»ºç´¢å¼•æ¡ç›®
        entry = PrefixEntry(
            token_hash=hash_key,
            token_ids=token_ids.copy(),
            block_ids=[b.block_id for b in blocks],
            ref_count=1,
            tenant_id=tenant_id,
        )
        
        # æ·»åŠ åˆ°ç´¢å¼•
        self._prefix_index[hash_key] = entry
        self._token_to_hash[tuple(token_ids)] = hash_key
        
        # æ ‡è®°å—ä¸ºå…±äº«
        for block in blocks:
            block.is_shared = True
    
    def release(
        self,
        request_id: str,
        token_ids: List[int],
    ) -> None:
        """é‡Šæ”¾å¤ç”¨çš„ KV
        
        å½“è¯·æ±‚å®Œæˆæ—¶è°ƒç”¨ï¼Œå‡å°‘å¼•ç”¨è®¡æ•°ã€‚
        """
        prefix_tuple = tuple(token_ids)
        if prefix_tuple not in self._token_to_hash:
            return
        
        hash_key = self._token_to_hash[prefix_tuple]
        entry = self._prefix_index.get(hash_key)
        
        if entry:
            entry.ref_count -= 1
            
            # å¼•ç”¨è®¡æ•°ä¸º 0 æ—¶æ¸…ç†
            if entry.ref_count <= 0:
                del self._prefix_index[hash_key]
                del self._token_to_hash[prefix_tuple]
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡"""
        total = self._stats["total_queries"]
        hit_rate = self._stats["cache_hits"] / total if total > 0 else 0.0
        
        return {
            **self._stats,
            "hit_rate": hit_rate,
            "index_size": len(self._prefix_index),
        }
```

---

## å•å…ƒæµ‹è¯•è¦æ±‚

åˆ›å»º `tests/unit/test_kv_runtime.py`ï¼š

```python
import pytest
import torch
from sageLLM.kv_runtime.blocks.multi_granular import (
    MultiGranularKVPool, KVPoolConfig, KVGranularity, StorageTier
)
from sageLLM.kv_runtime.hierarchy.tiered_storage import (
    TieredKVStorage, TierConfig
)
from sageLLM.kv_runtime.migration.hot_cold import (
    HotColdClassifier, KVMigrator
)
from sageLLM.kv_runtime.reuse.cross_request import CrossRequestKVCache


class TestMultiGranularKVPool:
    """å¤šç²’åº¦ KV æ± æµ‹è¯•"""
    
    def test_allocate_block_granularity(self):
        """æµ‹è¯•å—ç²’åº¦åˆ†é…"""
        config = KVPoolConfig(block_size=16)
        pool = MultiGranularKVPool(config)
        
        blocks = pool.allocate(
            sequence_id=1,
            request_id="req_1",
            num_tokens=64,
            layer_ids=[0, 1, 2],
        )
        
        assert len(blocks) == 4  # 64 / 16 = 4 blocks
    
    def test_allocate_token_granularity(self):
        """æµ‹è¯• token ç²’åº¦åˆ†é…"""
        config = KVPoolConfig()
        pool = MultiGranularKVPool(config)
        
        blocks = pool.allocate(
            sequence_id=1,
            request_id="req_1",
            num_tokens=10,
            layer_ids=[0],
            granularity=KVGranularity.TOKEN,
        )
        
        assert len(blocks) == 10
    
    def test_deallocate(self):
        """æµ‹è¯•é‡Šæ”¾"""
        pool = MultiGranularKVPool(KVPoolConfig())
        blocks = pool.allocate(1, "req_1", 16, [0])
        
        assert pool.get_stats()["total_blocks"] == 1
        
        pool.deallocate(blocks)
        
        assert pool.get_stats()["total_blocks"] == 0


class TestTieredKVStorage:
    """ä¸‰çº§å­˜å‚¨æµ‹è¯•"""
    
    @pytest.fixture
    def storage(self):
        return TieredKVStorage(
            hbm_config=TierConfig(
                tier=StorageTier.HBM,
                capacity_bytes=1024 * 1024,  # 1 MB
                bandwidth_gbps=900.0,
                latency_us=1.0,
                device_id=0,
            ),
            ddr_config=TierConfig(
                tier=StorageTier.DDR,
                capacity_bytes=4 * 1024 * 1024,  # 4 MB
                bandwidth_gbps=50.0,
                latency_us=100.0,
            ),
        )
    
    def test_tier_usage(self, storage):
        """æµ‹è¯•å±‚ä½¿ç”¨æƒ…å†µ"""
        usage = storage.get_tier_usage(StorageTier.HBM)
        assert usage.capacity_bytes == 1024 * 1024
        assert usage.utilization == 0.0


class TestHotColdClassifier:
    """å†·çƒ­åˆ†ç±»å™¨æµ‹è¯•"""
    
    def test_classify_hot(self):
        """æµ‹è¯•çƒ­å—åˆ†ç±»"""
        classifier = HotColdClassifier()
        
        block = KVBlockDescriptor(
            block_id=1,
            granularity=KVGranularity.BLOCK,
            layer_ids=[0],
            head_ids=[],
            token_range=(0, 16),
            sequence_id=1,
            request_id="req_1",
        )
        block.access_frequency = 2.0  # é«˜é¢‘è®¿é—®
        
        assert classifier.classify(block) == "hot"
    
    def test_classify_cold(self):
        """æµ‹è¯•å†·å—åˆ†ç±»"""
        classifier = HotColdClassifier(cold_timeout_s=1.0)
        
        block = KVBlockDescriptor(
            block_id=1,
            granularity=KVGranularity.BLOCK,
            layer_ids=[0],
            head_ids=[],
            token_range=(0, 16),
            sequence_id=1,
            request_id="req_1",
        )
        block.last_access_time = time.time() - 100  # å¾ˆä¹…æœªè®¿é—®
        block.access_frequency = 0.01
        
        assert classifier.classify(block) == "cold"


class TestCrossRequestKVCache:
    """è·¨è¯·æ±‚ç¼“å­˜æµ‹è¯•"""
    
    def test_reuse_exact_match(self):
        """æµ‹è¯•ç²¾ç¡®åŒ¹é…å¤ç”¨"""
        pool = MultiGranularKVPool(KVPoolConfig())
        cache = CrossRequestKVCache(pool)
        
        # ç¬¬ä¸€ä¸ªè¯·æ±‚
        token_ids = [1, 2, 3, 4, 5]
        blocks = pool.allocate(1, "req_1", len(token_ids), [0])
        cache.commit("req_1", token_ids, blocks)
        
        # ç¬¬äºŒä¸ªè¯·æ±‚å°è¯•å¤ç”¨
        result = cache.try_reuse("req_2", token_ids)
        
        assert result.reused
        assert result.matched_tokens == 5
        assert result.reuse_ratio == 1.0
    
    def test_reuse_prefix_match(self):
        """æµ‹è¯•å‰ç¼€åŒ¹é…å¤ç”¨"""
        pool = MultiGranularKVPool(KVPoolConfig())
        cache = CrossRequestKVCache(pool)
        
        # æäº¤å‰ç¼€
        prefix = [1, 2, 3]
        blocks = pool.allocate(1, "req_1", len(prefix), [0])
        cache.commit("req_1", prefix, blocks)
        
        # ç”¨æ›´é•¿çš„åºåˆ—æŸ¥è¯¢
        result = cache.try_reuse("req_2", [1, 2, 3, 4, 5])
        
        assert result.reused
        assert result.matched_tokens == 3
        assert result.reuse_ratio == 0.6
```

---

## æ¥å£çº¦å®š

### è¾“å…¥æ¥å£

| æ¥å£ | æ¥æº | è¯´æ˜ |
|------|------|------|
| `PrefixIndex` | `prefix_reuse` | å‰ç¼€ç´¢å¼•ï¼ˆå¯é€‰é›†æˆï¼‰ |
| `ScheduleOutput` | `runtime/scheduler` | è°ƒåº¦ç»“æœ |

### è¾“å‡ºæ¥å£

| æ¥å£ | ç›®æ ‡ | è¯´æ˜ |
|------|------|------|
| `KVBudget` | `runtime/scheduler` | KV é¢„ç®— |
| `KVMetrics` | `benchmarks` | KV æŒ‡æ ‡ï¼ˆå‘½ä¸­ç‡ã€è¿ç§»æµé‡ï¼‰ |

---

## éªŒæ”¶æ ‡å‡†

- [ ] å¤šç²’åº¦ KV å—æ”¯æŒ BLOCK/TOKEN/HEAD/LAYER å››ç§ç²’åº¦
- [ ] ä¸‰çº§å­˜å‚¨æ”¯æŒ HBM/DDRï¼ŒNVMe å¯é€‰
- [ ] å†·çƒ­åˆ†ç±»å™¨å‡†ç¡®ç‡ > 90%ï¼ˆåœ¨æ¨¡æ‹Ÿè´Ÿè½½ä¸‹ï¼‰
- [ ] è·¨è¯·æ±‚å¤ç”¨ä¸ prefix_reuse æ¨¡å—æ­£ç¡®é›†æˆ
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%
- [ ] ä»£ç é€šè¿‡ `ruff check` å’Œ `mypy`

---

## è¾“å‡ºç‰©æ¸…å•

```
kv_runtime/
â”œâ”€â”€ __init__.py              # æ›´æ–°å¯¼å‡º
â”œâ”€â”€ blocks/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ multi_granular.py    # âœ… å®Œæ•´å®ç°
â”œâ”€â”€ hierarchy/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ tiered_storage.py    # âœ… å®Œæ•´å®ç°
â”œâ”€â”€ migration/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ hot_cold.py          # âœ… å®Œæ•´å®ç°
â””â”€â”€ reuse/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ cross_request.py     # âœ… å®Œæ•´å®ç°

tests/unit/
â””â”€â”€ test_kv_runtime.py       # âœ… æµ‹è¯•æ–‡ä»¶
```
